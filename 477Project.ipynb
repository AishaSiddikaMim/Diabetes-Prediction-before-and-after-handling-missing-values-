{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/diabetes (1).csv'\n",
        "diabetes_data = pd.read_csv(file_path)\n",
        "\n",
        "total_rows, total_columns = diabetes_data.shape\n",
        "print(f\"Total number of rows: {total_rows}\")\n",
        "print(f\"Total number of columns: {total_columns}\")\n",
        "\n",
        "# Split data into features and target\n",
        "X = diabetes_data.drop(columns=['Outcome'])\n",
        "y = diabetes_data['Outcome']\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "print(\"Decision Tree Classifier Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_test, dt_pred))\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Classifier Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_pred))\n",
        "\n",
        "# KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, knn_pred))\n",
        "\n",
        "# SVM classifier\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, svm_pred))\n",
        "\n",
        "# Initial accuracies\n",
        "initial_accuracies = {\n",
        "    'Decision Tree': dt_accuracy,\n",
        "    'Random Forest': rf_accuracy,\n",
        "    'KNN': knn_accuracy,\n",
        "    'SVM': svm_accuracy\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKZx3WFJz6Mp",
        "outputId": "89651280-1e09-46cc-9d38-1492277bf8dc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows: 768\n",
            "Total number of columns: 9\n",
            "Decision Tree Classifier Accuracy: 0.7056277056277056\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.72      0.76       151\n",
            "           1       0.56      0.69      0.62        80\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.69      0.70      0.69       231\n",
            "weighted avg       0.73      0.71      0.71       231\n",
            "\n",
            "Random Forest Classifier Accuracy: 0.7489177489177489\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.81       151\n",
            "           1       0.63      0.65      0.64        80\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.72      0.73      0.72       231\n",
            "weighted avg       0.75      0.75      0.75       231\n",
            "\n",
            "KNN Accuracy: 0.6926406926406926\n",
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       151\n",
            "           1       0.56      0.51      0.54        80\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.66      0.65      0.65       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "SVM Accuracy: 0.7489177489177489\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.81       151\n",
            "           1       0.65      0.60      0.62        80\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.75      0.75      0.75       231\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your chosen dataset (replace 'path_to_your_dataset.csv' with your actual file path)\n",
        "df = pd.read_csv('/content/diabetes (1).csv')\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Introduce 35% missing values\n",
        "missing_rate = 0.35\n",
        "n_missing_samples = int(np.floor(missing_rate * df.size))\n",
        "\n",
        "# Randomly select indices to be replaced with NaN\n",
        "missing_samples = np.random.choice(df.size, n_missing_samples, replace=False)\n",
        "\n",
        "# Flatten the DataFrame to introduce NaNs and then reshape it back\n",
        "flat_df = df.values.flatten()\n",
        "flat_df[missing_samples] = np.nan\n",
        "df_with_missing = pd.DataFrame(flat_df.reshape(df.shape), columns=df.columns)\n",
        "\n",
        "# Save the dataset with missing values\n",
        "df_with_missing.to_csv('dataset_with_missing_values.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9fZy3enzOke",
        "outputId": "9cf97b28-f04e-428a-bca5-6171d208b671"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataFrame called 'original_df' with your dataset\n",
        "# Replace 'original_df' with the actual name of your DataFrame\n",
        "\n",
        "# Calculate the number of missing values to create\n",
        "missing_percentage = 0.35\n",
        "total_cells = df.shape[0] * df.shape[1]\n",
        "missing_cells = int(total_cells * missing_percentage)\n",
        "\n",
        "# Randomly select cells to be set as missing\n",
        "missing_indices = np.random.choice(df.index, size=missing_cells, replace=True)\n",
        "missing_columns = np.random.choice(df.columns, size=missing_cells, replace=True)\n",
        "\n",
        "# Set the selected cells to NaN\n",
        "for idx, col in zip(missing_indices, missing_columns):\n",
        "    df.at[idx, col] = np.nan\n",
        "\n",
        "# Now 'original_df' will have approximately 35% missing values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P3sqnwszRdm",
        "outputId": "9159b876-92c8-47a4-eb82-494db64784e3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataFrame called 'original_df' with your dataset\n",
        "# Replace 'original_df' with the actual name of your DataFrame\n",
        "\n",
        "# Print previous missing values\n",
        "previous_missing_values = df.isnull().sum().sum()\n",
        "print(\"Previous missing values:\", previous_missing_values)\n",
        "\n",
        "# Calculate the number of missing values to create\n",
        "missing_percentage = 0.35\n",
        "total_cells = df.shape[0] * df.shape[1]\n",
        "missing_cells = int(total_cells * missing_percentage)\n",
        "\n",
        "# Randomly select cells to be set as missing\n",
        "missing_indices = np.random.choice(df.index, size=missing_cells, replace=True)\n",
        "missing_columns = np.random.choice(df.columns, size=missing_cells, replace=True)\n",
        "\n",
        "# Set the selected cells to NaN\n",
        "for idx, col in zip(missing_indices, missing_columns):\n",
        "    df.at[idx, col] = np.nan\n",
        "\n",
        "# Print new missing values\n",
        "new_missing_values = df.isnull().sum().sum()\n",
        "print(\"New missing values (35%):\", new_missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mefzLhVvzUvO",
        "outputId": "19b43903-e4b5-42b6-928d-cec1a0df81bf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous missing values: 2054\n",
            "New missing values (35%): 3526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean imputation for numeric columns\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df.mean())\n",
        "\n",
        "# Mode imputation for categorical columns\n",
        "categorical_cols = df.select_dtypes(exclude='number').columns\n",
        "df[categorical_cols] = df[categorical_cols].fillna(df.mode().iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K73ynWAzZ6q",
        "outputId": "0c374303-c9df-4f1f-dd90-40fd1cfcd7a5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward Fill/Backward Fill:\n",
        "\n",
        "#Propagate the last known value forward to fill missing values (forward fill) or propagate the next known value backward (backward fill).\n",
        "#Suitable for time series data where missing values are assumed to have similar values to adjacent observations.\n",
        "# Forward fill\n",
        "df_ffill = df.ffill()\n",
        "\n",
        "# Backward fill\n",
        "df_bfill = df.bfill()\n",
        "\n",
        "#tnterpolation:\n",
        "#Estimate missing values based on the values of neighboring data points.\n",
        "#Suitable for numeric data with a linear relationship between variables.\n",
        "# Linear interpolation\n",
        "df_interpolated = df.interpolate(method='linear')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpVExB8LzbGA",
        "outputId": "88527c1a-3b2c-40e9-89b0-81e015071324"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Create KNN imputer object\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# Apply imputation\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zMenw4AzcTc",
        "outputId": "659ee0a0-d61e-4b57-fac8-e694313c0c18"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().any()\n",
        "\n",
        "# Print columns with missing values\n",
        "print(\"Columns with missing values:\")\n",
        "print(missing_values[missing_values].index.tolist())\n",
        "\n",
        "# Print rows with missing values\n",
        "print(\"\\nRows with missing values:\")\n",
        "print(df[df.isnull().any(axis=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQqL3W0ezcwy",
        "outputId": "0c4df139-599d-43af-8a72-e115f0d30bfb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values:\n",
            "[]\n",
            "\n",
            "Rows with missing values:\n",
            "Empty DataFrame\n",
            "Columns: [Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "if df.isnull().values.any():\n",
        "    # Print columns with missing values\n",
        "    print(\"Columns with missing values:\")\n",
        "    print(df.columns[df.isnull().any()].tolist())\n",
        "else:\n",
        "    print(\"NO MISSING VALUE AVAILABLE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3jLiil1zfZ4",
        "outputId": "26df014f-241b-4f44-c1cd-ee707a15984c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO MISSING VALUE AVAILABLE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "# Extract the target variable (y)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# Extract the feature variables (X)\n",
        "#X = df.drop(columns=[\"Outcome\"])\n",
        "# Defining X variables\n",
        "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-f3FMPzhCf",
        "outputId": "c785214a-d5da-4de5-9ffe-9f40a90ca97e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.astype(int)\n",
        "\n",
        "print(y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWZbbRbtzjRp",
        "outputId": "ed6e0bd8-598e-4da3-d941-46bd023ea9e6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/diabetes (1).csv'\n",
        "diabetes_data = pd.read_csv(file_path)\n",
        "\n",
        "# Split data into features and target\n",
        "X = diabetes_data.drop(columns=['Outcome'])\n",
        "y = diabetes_data['Outcome']\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "print(\"Decision Tree Classifier Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_test, dt_pred))\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Classifier Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_pred))\n",
        "\n",
        "# KNN classifier with Hyperparameter Tuning\n",
        "knn_param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5)\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "best_knn = grid_search_knn.best_estimator_\n",
        "best_knn.fit(X_train, y_train)\n",
        "knn_pred = best_knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, knn_pred))\n",
        "\n",
        "# SVM classifier\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, svm_pred))\n",
        "\n",
        "# Apriori Algorithm\n",
        "frequent_itemsets = apriori(diabetes_data.astype(bool), min_support=0.1, use_colnames=True)\n",
        "apriori_rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
        "print(\"Number of Apriori Rules:\", len(apriori_rules))\n",
        "\n",
        "# FP-Growth Algorithm\n",
        "frequent_itemsets_fp = fpgrowth(diabetes_data.astype(bool), min_support=0.1, use_colnames=True)\n",
        "fp_growth_rules = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.7)\n",
        "print(\"Number of FP-Growth Rules:\", len(fp_growth_rules))\n",
        "\n",
        "# Initial and Final accuracies\n",
        "initial_accuracies = {\n",
        "    'Decision Tree': dt_accuracy,\n",
        "    'Random Forest': rf_accuracy,\n",
        "    'KNN': knn_accuracy,\n",
        "    'SVM': svm_accuracy\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVEFj6DI5yZu",
        "outputId": "e6d6250d-8c4e-4204-e441-b4d3dfc1c7fe"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Accuracy: 0.7467532467532467\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79        99\n",
            "           1       0.62      0.73      0.67        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.74      0.73       154\n",
            "weighted avg       0.76      0.75      0.75       154\n",
            "\n",
            "Random Forest Classifier Accuracy: 0.7272727272727273\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79        99\n",
            "           1       0.62      0.62      0.62        55\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.70      0.70      0.70       154\n",
            "weighted avg       0.73      0.73      0.73       154\n",
            "\n",
            "KNN Accuracy: 0.7142857142857143\n",
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78        99\n",
            "           1       0.60      0.58      0.59        55\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.69      0.68      0.69       154\n",
            "weighted avg       0.71      0.71      0.71       154\n",
            "\n",
            "SVM Accuracy: 0.7272727272727273\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.79        99\n",
            "           1       0.63      0.56      0.60        55\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.70      0.69      0.70       154\n",
            "weighted avg       0.72      0.73      0.72       154\n",
            "\n",
            "Number of Apriori Rules: 8116\n",
            "Number of FP-Growth Rules: 8116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/diabetes (1).csv'\n",
        "diabetes_data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert dataset to boolean type for association rule mining\n",
        "diabetes_data_bool = diabetes_data.astype(bool)\n",
        "\n",
        "# Measure time for Apriori\n",
        "start_time = time.time()\n",
        "frequent_itemsets_apriori = apriori(diabetes_data_bool, min_support=0.1, use_colnames=True)\n",
        "apriori_rules = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=0.7)\n",
        "apriori_time = time.time() - start_time\n",
        "print(\"Apriori execution time:\", apriori_time)\n",
        "print(\"Number of Apriori Rules:\", len(apriori_rules))\n",
        "\n",
        "# Measure time for FP-Growth\n",
        "start_time = time.time()\n",
        "frequent_itemsets_fp = fpgrowth(diabetes_data_bool, min_support=0.1, use_colnames=True)\n",
        "fp_growth_rules = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.7)\n",
        "fp_growth_time = time.time() - start_time\n",
        "print(\"FP-Growth execution time:\", fp_growth_time)\n",
        "print(\"Number of FP-Growth Rules:\", len(fp_growth_rules))\n",
        "\n",
        "# Compare times\n",
        "if apriori_time < fp_growth_time:\n",
        "    print(\"Apriori is more efficient.\")\n",
        "else:\n",
        "    print(\"FP-Growth is more efficient.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oggdEusF7TRi",
        "outputId": "d09f9de3-90ac-422f-f215-61c473732024"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori execution time: 0.41843533515930176\n",
            "Number of Apriori Rules: 8116\n",
            "FP-Growth execution time: 0.2651960849761963\n",
            "Number of FP-Growth Rules: 8116\n",
            "FP-Growth is more efficient.\n"
          ]
        }
      ]
    }
  ]
}